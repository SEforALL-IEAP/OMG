{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783afe1a",
   "metadata": {},
   "source": [
    "# Open Source Spatial Electrification Toolkit for Mini Grids (OnSSET-MG)\n",
    "\n",
    "**OnSSET-MG** is a modified version of the Open Source Spatial Electrification Toolkit ([OnSSET](https://github.com/OnSSET)) that is dedicated to the Mini Grid design. The tool performs two key tasks: a) sizing of mini grid components and b) automated design of the distribution network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9918a",
   "metadata": {},
   "source": [
    "Developed by: [SEforALL UIEP Team](https://www.seforall.org/programmes/universal-integrated-energy-plans) \n",
    "\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a951a",
   "metadata": {},
   "source": [
    "This notebook is structured as follows: \n",
    "\n",
    "1. **Importing python libraries:** This section outlines the process for importing the required Python libraries or packages needed for the analysis\n",
    "2. **Defining working space:** Define the folder structure for storing and organizing data used in the notebook. This includes specifying locations for downloaded datasets, processed data, and any output files\n",
    "\n",
    "3. **Importing Datasets:** Import the key datasets required to run the code. This includes:\n",
    "    * Community alpha shape (cluster) --> vector polygon\n",
    "    * Building dataset --> vector polygon (or point)\n",
    "    * PV related environmental data --> .csv format\n",
    "    * Load profile -->  .csv format<br>\n",
    "    <br>\n",
    "4. **Technical and economic assumptions:** This section outlines any economic and technical assumptions made during the analysis\n",
    "\n",
    "5. **Optimization for Generation Sizing:** This section describes the optimization process for determining the optimal hybrid generation based on the imported data\n",
    "\n",
    "6. **Distribution Network Sizing:** Here a design of the distribution network for the Mini grid is generated\n",
    "\n",
    "7. **Analysis:** Some analysis are conducted highlighting the flexibility and advantages of using Python\n",
    "\n",
    "8. **Results:** Examples on how to export results from the model are showed\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72b855",
   "metadata": {},
   "source": [
    "## 1. Importing python libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5322690",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are some essential Python packages for data science tasks. \n",
    "## They are widely used in various scripts because their combination allows to perform a powerful series of operations on data.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## There are packages related to working with geospatial data and performing spatial analysis. \n",
    "## They allow you to represent and manipulate geographical features and data\n",
    "\n",
    "#import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import LineString, Point, MultiLineString, Polygon, MultiPoint\n",
    "from shapely.ops import linemerge, nearest_points, unary_union, split, substring, voronoi_diagram\n",
    "from shapely import minimum_rotated_rectangle, unary_union\n",
    "from scipy.spatial import Voronoi, cKDTree\n",
    "import networkx as nx\n",
    "from scipy.optimize import Bounds, differential_evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e71e0",
   "metadata": {},
   "source": [
    "We also need to import some additional functions coded by the developers to:\n",
    "* Optimize MG component sizing --> [Hybrids.py](./Hybrids.py)\n",
    "* Automation of distribution design --> [dist_funcs.py](./dist_funcs.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13111e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrids import *\n",
    "from dist_funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89141141",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46570d96",
   "metadata": {},
   "source": [
    "## 2. Defining folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the root directory\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "\n",
    "## Input folder \n",
    "admin_path = os.path.join(ROOT_DIR, \"Input_data\")\n",
    "if not os.path.exists(admin_path):\n",
    "    os.makedirs(admin_path)\n",
    "    \n",
    "##PV Data Folder\n",
    "pv_data_folder = admin_path + \"\\\\\" + \"pv\"\n",
    "if not os.path.exists(pv_data_folder):\n",
    "    os.makedirs(pv_data_folder)\n",
    "\n",
    "## Output folder \n",
    "outpath = os.path.join(ROOT_DIR, \"Output_Data\")\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a07d8d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fafe16b",
   "metadata": {},
   "source": [
    "## 3. Importing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed9fdf",
   "metadata": {},
   "source": [
    "The model effectively runs based on four datasets:\n",
    "\n",
    "\n",
    "1. **Community alpha shape (cluster)** --> vector polygon data that characterize the boundary area of the community<br>\n",
    "\n",
    "2. **PV related environmental data** --> .csv format dataset that provides info re the Global Horizontal Irradiation (GHI) and temperature of the location\n",
    "\n",
    "3. **Building dataset**--> vector polygon (or point) data that characterize the structures/buildings withing the community\n",
    "\n",
    "4. **Load profile** --> .csv format dataset that aggregates the total electricity demand for the mini grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468eb47-ad39-49ee-96b0-b429da750abf",
   "metadata": {},
   "source": [
    "### First, please provide the CRS suitable for your Area of Interest\n",
    "\n",
    "When calculating distances it is important to choose a coordinate system that represents distances correctly in your area of interest. The coordinate system that is given below is the World Mercator, these coordinate system works well for Sub Saharan Africa but the distortions get larger as you move away from the equator.\n",
    "\n",
    "In order to select your own coordinate system go to [epsg.io](http://epsg.io/) and type in your area of interest, this will give you a list of coordinate systems to choose from. Once you have selected your coordinate system replace the numbers below with the numbers from your coordinate system **(keep the \\\"EPSG\\\" part)**.\n",
    "\n",
    "**NOTE** When selecting your projection (target) coordinate system make sure that you select a system with the unit of meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_crs = 'EPSG:4326'   ### WGS84 \n",
    "target_crs = 'EPSG:32615' ### For Guatemala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c39213",
   "metadata": {},
   "source": [
    "### And the name of the community\n",
    "\n",
    "Note that this should match the name of the community in the GIS layer containing the community boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "community = \"ALDEA MANAJA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb54d8e-93c1-4966-8aa0-b9be184343a0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61359a72",
   "metadata": {},
   "source": [
    "### 3.1 Community alpha shape (cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e835729",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the layer indicating the alpha shape of the community (.shp | .gpkg | .geojson)\n",
    "cluster_polygons = gpd.read_file(r'Input_Data\\{}.gpkg'.format(community))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ecc1bc",
   "metadata": {},
   "source": [
    "Data exploration is a crucial step in any data analysis process. It allows identification of key characteristics and potential issues within the data. While the data stored in *cluster_polygons* has been preprocessed in QGIS for this specific exercise, the script's functionality relies on a consistent data structure that aligns with its expected input.  From the variable *cluster_polygons*, there are three values that can be extracted: id, COMUNIDAD and geometry, being of interest the use of the geometry column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizing the community in focus\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "cluster_polygons.plot(ax=ax, edgecolor='black', alpha=0.2)\n",
    "ax.set_aspect('equal', 'box')\n",
    "txt = ax.set_title('{}'.format(community), size=8)\n",
    "ax.tick_params(axis='x', labelcolor='black', labelsize=6)\n",
    "ax.tick_params(axis='y', labelcolor='black', labelsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e3b4ff-3e41-4187-960e-c3358d6058cc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6c5a1",
   "metadata": {},
   "source": [
    "### 3.2 Environmental characteristics: retrieving GHI and temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb91e4a",
   "metadata": {},
   "source": [
    "The Global Horizontal Irradiation (GHI) and temperature data can be retrieved from [renewables ninja](https://www.renewables.ninja). Before proceeding, please consult the [documentation](https://www.renewables.ninja/documentation) as creating a user account and password is necessary to generate a token for downloading specific data. You can do this by following the steps below:\n",
    "1. Create a free account on the Renewables.ninja [website](https://www.renewables.ninja/register). Once registered, users gain the ability to download datasets and utilize the API for programmatic data retrieval.<br>\n",
    "<br>\n",
    "2. Log in. To access a personal API token, navigate to the profile by clicking on the symbol in the top right corner (usually a profile picture or icon) on [profile](https://www.renewables.ninja/profile).<br>\n",
    "<br>\n",
    "3. Within the profile settings, users can find their unique API token. This token should be copied and pasted between quotation marks (token = 'your_token_here') when using the API in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = cluster_polygons.geometry.centroid.x[0]    ## retrieved using the centroid of the polygon\n",
    "latitude = cluster_polygons.geometry.centroid.y[0]     ## retrieved using the centroid of the polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ab42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = ''     ## To be retrieved through renewables ninja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ce295",
   "metadata": {},
   "source": [
    "**Execute the data acquisition function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pv_data(latitude, longitude, token, pv_data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be12bbc",
   "metadata": {},
   "source": [
    "By executing the function a Comma-Separated Values (CSV) file named pv_data_lat_yyyy_long_xxxx.csv should have been downloaded. In case that there have been changes in the latitude, longitude coordinates, the name of the file (yyyy,xxxx) will be different. This file contains the following data:\n",
    "\n",
    "+ time: Structured in hourly format.\n",
    "+ ghi: Units are in watt-hours (Wh).\n",
    "+ temperature: Units are in degrees Celsius (°C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7139b",
   "metadata": {},
   "source": [
    "| time                     | ghi | temperature |\n",
    "|--------------------------|-----|-------------|\n",
    "| 2019-12-31 18:00:00-06:00| 0.0 | 23.407       |\n",
    "| 2019-12-31 19:00:00-06:00| 0.0 | 22.95       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4bd985",
   "metadata": {},
   "source": [
    "Finally, the read_environmental_data function defines two variables to extract 8,760 values for GHI and temperature. The function is designed to output two NumPy arrays containing this data. \n",
    "\n",
    "**Important Note**: If better access to higher-quality environmental data is available, it should be formatted identically to the expected structure of hourly_ghi and hourly_temp.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c017827",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_ghi, hourly_temp = read_environmental_data(os.path.join(pv_data_folder, 'pv_data_lat_{}_long_{}.csv'.format(latitude, longitude)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f1011",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Generate the array for hours of the year\n",
    "hours_of_year = np.arange(8760)  # Array from 0 to 8759\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(hours_of_year, hourly_ghi, marker='', linestyle='-', color='b')\n",
    "# Labeling the axes\n",
    "plt.xlabel('Hours of the Year')\n",
    "plt.ylabel('Hourly GHI (W/m²)')\n",
    "# Adding a title\n",
    "plt.title('Hourly GHI over the Year for {}'.format(community))\n",
    "# Show grid\n",
    "plt.grid(True)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25a8b8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137c428",
   "metadata": {},
   "source": [
    "### 3.3 Building footprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0522330",
   "metadata": {},
   "source": [
    "Building footprints provide information on the location of houses to be electrified, which is crucial for determining the size of the minigrid's distribution network. Here, we are using data from [Google-Microsoft Open Buildings by VIDA](https://beta.source.coop/vida/google-microsoft-open-buildings/). The data can be downloaded directly from the link under the Download section on the provided link. \n",
    "\n",
    "The downloaded file will be in .fgb format and is quite large (around 2.2 GB for Guatemala). To optimize local resources, it is a good practice to clip the data in QGIS before using it in a notebook. Sample buildings withing \"Input_Data\" for \"Aldea Manaja\" have already been extracted for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff77b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "households = gpd.read_file(r'Input_Data\\{} blds.gpkg'.format(community))\n",
    "households.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c4b11",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0974d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizing structures within the community in focus\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cluster_polygons.plot(ax=ax, edgecolor='black', alpha=0.2)\n",
    "households.plot(ax=ax, edgecolor='red', alpha=0.2)\n",
    "ax.set_aspect('equal', 'box')\n",
    "txt = ax.set_title('{}'.format(community), size=8)\n",
    "ax.tick_params(axis='x', labelcolor='black', labelsize=6)\n",
    "ax.tick_params(axis='y', labelcolor='black', labelsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696aad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and labels\n",
    "bins = [0, 20, 50, 150, float('inf')]\n",
    "labels = ['<20 m2', '20-50 m2', '50-150 m2', '>150 m2']\n",
    "\n",
    "# Calculate the statistics without adding a new column\n",
    "area_brackets = pd.cut(households['area_in_meters'], bins=bins, labels=labels, right=False)\n",
    "bracket_stats = area_brackets.value_counts().sort_index()\n",
    "\n",
    "# Add the total sum as value per column\n",
    "for label in labels:\n",
    "    cluster_polygons[label] = bracket_stats[label]\n",
    "\n",
    "\n",
    "print (\"Total structures:\", households.shape[0])\n",
    "print (bracket_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e46210",
   "metadata": {},
   "source": [
    "### 3.2 Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d353c",
   "metadata": {},
   "source": [
    "There are two primary methods for acquiring demand data:\n",
    "\n",
    "**OPTION 1.** Rough assumption of type of customers (based on developers experience) + indicative load curves per type\n",
    "\n",
    "**OPTION 2.** Site-Specific Data --> more detailed load profile per type of user (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eccdcb",
   "metadata": {},
   "source": [
    " ------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d680585",
   "metadata": {},
   "source": [
    "#### OPTION 1. Load profile estimation based on predefined archetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142fb4e",
   "metadata": {},
   "source": [
    "Under this approach, number of customers and demand load curves per type of customer are derived based on empirical data. You can find the sample load curves in [Input_data](./Input_data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d4c08",
   "metadata": {},
   "source": [
    "#### Rough prediction of customer per type (residential bundle A, bundle B, bundle C, SME or PUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3adf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonablecons = 1        ## Connectivity rate of structures - for now this value should not be changed \n",
    "smeshare = 0.08             ## Share of sme customers as % of total potential connections\n",
    "bundleCshare = 0.08         ## Share of Residential Bundle C customers as % of total potential connections\n",
    "bundleBshare = 0.36         ## Share of Residential Bundle B customers as % of total potential connections\n",
    "\n",
    "cluster_polygons[\"Connections_All\"] = np.ceil(cluster_polygons[\"<20 m2\"] + \n",
    "                               cluster_polygons[\"20-50 m2\"]+ \n",
    "                               cluster_polygons[\"50-150 m2\"]+ \n",
    "                               cluster_polygons[\">150 m2\"]).astype(int)\n",
    "\n",
    "cluster_polygons[\"Potential_Con\"] = np.ceil(cluster_polygons[\"Connections_All\"]*reasonablecons)\n",
    "\n",
    "def assignPUoE(a, b, c, d, e):\n",
    "    puoe = int(round(-2.913362564 + (-0.00415764*a) + (0.008440603*b) + (0.016433547*c) + (0.722331464*d) + (-0.040674586*e),0))\n",
    "    if puoe <=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return puoe\n",
    "\n",
    "cluster_polygons[\"PUoE\"] = cluster_polygons.apply(lambda row: assignPUoE(row[\"<20 m2\"],\n",
    "                                             row[\"20-50 m2\"],\n",
    "                                             row[\"50-150 m2\"],\n",
    "                                             row[\">150 m2\"],\n",
    "                                             0), axis=1)\n",
    "\n",
    "cluster_polygons[\"SME\"] = np.ceil((cluster_polygons[\"Potential_Con\"] - cluster_polygons[\"PUoE\"])*smeshare)\n",
    "    \n",
    "cluster_polygons[\"ResC\"] = np.ceil((cluster_polygons[\"Potential_Con\"] - cluster_polygons[\"PUoE\"])*bundleCshare)\n",
    "                     \n",
    "cluster_polygons[\"ResB\"] = np.ceil((cluster_polygons[\"Potential_Con\"] - cluster_polygons[\"PUoE\"])*bundleBshare)\n",
    "                     \n",
    "cluster_polygons[\"ResA\"] = (cluster_polygons[\"Potential_Con\"] - cluster_polygons[\"PUoE\"] - cluster_polygons[\"SME\"] - cluster_polygons[\"ResC\"]- cluster_polygons[\"ResB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf328c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dabd53e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7770c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_curve = calc_load_curve(tier_load, total_demand)\n",
    "load_curve = calc_load_curve(cluster_polygons[\"ResA\"][0],\n",
    "                             cluster_polygons[\"ResB\"][0],\n",
    "                             cluster_polygons[\"ResC\"][0],\n",
    "                             cluster_polygons[\"SME\"][0],\n",
    "                             cluster_polygons[\"PUoE\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76c121",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd63e06",
   "metadata": {},
   "source": [
    "#### OPTION 2. Site-Specific Data (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e2972",
   "metadata": {},
   "source": [
    "This approach requires that demand load curves adhere to a specific data structure to be compatible with the *load_curve* variable. This format requires 8760 hourly values representing hourly consumption in kW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85b3c1",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# demand_csv = pd.read_csv('PATH_TO_CSV')\n",
    "# load_curve = demand_csv['Demand_col']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a6858",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef83be",
   "metadata": {},
   "source": [
    "Regardless of the approach used the *annual_demand* is a variable should be specified for the use to calculate LCOE.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c18557",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_demand = sum(load_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c3fe9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b3c63",
   "metadata": {},
   "source": [
    "## 4. Technical and economic assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc591d",
   "metadata": {},
   "source": [
    "### 4.1 Technical and economic assumptions for optimisation of the generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81318c33",
   "metadata": {},
   "source": [
    "The following technical and economic parameters are used for the optimization of generation in the microgrid. Please update these values based on the specific local context of analysis to ensure accurate results. Be mindful of units, as inconsistencies can lead to unexpected outcomes.\n",
    "\n",
    "**General parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d003b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year=2024\n",
    "end_year=2049\n",
    "discount_rate=0.08      ##The annual rate of return expected on an investment over the project's lifetime. This value is expressed as a percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea4bf3",
   "metadata": {},
   "source": [
    "**Diesel generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diesel_price=0.872     ## Diesel Price (USD/liter): The cost of diesel fuel used for generator operation\n",
    "diesel_cost=350        ## Diesel Generator Cost (USD/kW): The initial capital cost of purchasing and installing a diesel generator, per kilowatt of rated power\n",
    "diesel_om=0.1           ## Diesel Operational and mainenance Cost (USD/kW/year): The annual cost of operating and maintaining the diesel generator, share of CAPEX\n",
    "diesel_life=10         ## Diesel Generator Lifetime (years): The expected number of years the diesel generator will be operational before requiring replacement\n",
    "diesel_limit=0.5       ## Diesel Limit (0-1): This value sets the maximum allowable contribution of the diesel generator to the microgrid's annual electricity generation. It is expressed as a decimal between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d428de",
   "metadata": {},
   "source": [
    "**Batteries | Storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a825af",
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_cost=400           ## Battery Capital Cost (USD/kWh): The initial capital cost of purchasing and installing a battery storage system, per kilowatt-hour of storage capacity\n",
    "full_life_cycles=2000      ## Battery Lifetime (cycles): The expected number of full charge/discharge cycles the battery can undergo before reaching its end of life\n",
    "battery_inverter_cost=250  ## Battery Inverter Cost (USD/kW): The initial capital cost of purchasing and installing a battery inverter, per kilowatt of power\n",
    "battery_inverter_life=20   ## Battery Inverter Lifetime (years): The expected number of years the battery inverter will be operational before requiring replacement\n",
    "n_chg=0.90                 ## Battery Charging Efficiency (0-1): This parameter represents the efficiency of the battery charging process, accounting for energy losses during charging cycles. It is expressed as a decimal between 0 and 1\n",
    "n_dis=0.9                  ## Battery Discharging Efficiency (0-1): This parameter represents the efficiency of the battery discharging process, accounting for energy losses during discharging cycles. It is expressed as a decimal between 0 and 1\n",
    "dod_max=0.9                ## Dept-of-discharge (DOD) (0-1): DOD represents the percentage of a battery's total capacity that has been discharged in a single cycle, relative to its full charge capacity. It is expressed as a decimal between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc2b5c",
   "metadata": {},
   "source": [
    "**Solar panels  & Inverter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_cost=1200          ## PV Panel Cost (USD/kWp): The initial capital cost of purchasing and installing photovoltaic (PV) panels, per watt-peak (Wp) of rated power output\n",
    "pv_om=0.025           ## PV O&M Cost (USD/kWp/year): The annual cost of operating and maintaining the PV system, share of CAPEX. This includes costs for cleaning, monitoring, and minor repairs\n",
    "pv_inverter=175       ## PV Inverter Cost (USD/kWp): The initial capital cost of purchasing and installing a solar inverter, per kilowatt-peak (Wp) of PV installed capacity. If this cost is already included in the PV Panel Cost, set this value to 0\n",
    "charge_controller=0   ## Solar Charge Controller Cost (USD/kWp): The initial capital cost of purchasing and installing a solar charge controller, per kilowatt-peak (Wp) of PV panel capacity. If this cost is already included in the PV Panel Cost, set this value to 0\n",
    "pv_life=25            ## PV System Lifetime (years): The expected number of years the PV system (panels and inverter) will be operational before requiring replacement\n",
    "inv_eff=0.93          ## Inverter Efficiency (0-1): This parameter represents the efficiency of the inverter, which accounts for energy losses during conversion from DC to AC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ac5d0",
   "metadata": {},
   "source": [
    "**Minigrid parameter**\n",
    "\n",
    "Loss of Power Supply Probability (LPSP): This parameter indicates the reliability of the microgrid in supplying electricity. A lower LPSP signifies a more reliable system with a lower chance of power outages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330543ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpsp_max=0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45cf397",
   "metadata": {},
   "source": [
    "### 4.2 Technical and economic assumptions for optimisation of the generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e00f4b",
   "metadata": {},
   "source": [
    "The sizing process generates two outputs related to the distribution grid: a GeoJSON file containing detailed information about the designed grid, disaggregated by the type of line (trunk, lateral, service drop), and a point layer file for poles that specifies their spatial locations. By incorporating capital costs (installation costs) and operational costs into the analysis, it's possible to estimate the Levelized Cost of Energy (LCOE) for the entire distribution network. To calculate the LCOE, you'll need the following variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e08994",
   "metadata": {},
   "source": [
    "Cost of distribution lines (USD/km), which refers to the capital cost associated with installing one kilometer of distribution lines within the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a18f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_grid_km = 2000     ## LV line (0.2 – 0.4 kV) | Cost of low voltage distribution (approximation) -- overhead line, ABC type 100 mm2 Aluminium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea90abc",
   "metadata": {},
   "source": [
    "Cost of Poles (USD/Pole): which refers to the capital cost associated with installing supporting poles for distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_pole = 150+26+72.2+34+60     ## pole + overhead accessories + lightning protection + labour cost --> per pole\n",
    "pole_dist = 50                    ## meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f08dae",
   "metadata": {},
   "source": [
    "Service drop | Customer connection costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cost = 173 # overhead access. | meter | ready board+rectifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9236d1e",
   "metadata": {},
   "source": [
    "Operational & Maintenance costs (% initial investment): The annual cost of operating and maintaining the grid as percentage of initial investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae334368",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_om = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad774c",
   "metadata": {},
   "source": [
    "### 4.3 Labour and logistics costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9227ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour_cost =  100      ## Labour cost ~ 100 USD/kWp\n",
    "trans_cost = 27         ## Transportation of material | 27 USD/connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261ce5a",
   "metadata": {},
   "source": [
    "### 4.4 Selling general and administrative (SG&A) costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ec984",
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_cost = 18          ## $/connection/year ($1.5/con/month) which adds to the operation and maintenance costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf204c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost_sga = sga_cost*len(households)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf3838",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f8a26",
   "metadata": {},
   "source": [
    "## 5. Optimization for Generation Sizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b86bf",
   "metadata": {},
   "source": [
    "The *optimizer_de* function finds the least-cost design for a microgrid system. It considers economic and techincal factors through user-provided data (look step No 4). First, it calculates total electricity demand and defines acceptable ranges for PV, battery, and diesel generator capacities. Then, it creates an objective function (opt_func) that calculates the Levelized Cost of Energy (LCOE) for a specific system configuration. This involves simulating electricity generation from PV, battery usage, and diesel reliance based on hourly data. Finally, it employs a Differential Evolution algorithm to search for the combination of PV, battery, and diesel capacities that minimizes the overall LCOE for the microgrid system. \n",
    "\n",
    "The function returns the optimal system configuration (PV, battery, and diesel capacities) that achieves the minimum LCOE for the microgrid system, as well as other variables that are of interest to analize: unmet demand, diesel generaton share, investment, fuel cost, Operational & Maintenance Cost, battery energy and battery life. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_values_storage = []\n",
    "\n",
    "def optimizer_de(diesel_price,\n",
    "                 hourly_ghi,\n",
    "                 hourly_temp,\n",
    "                 load_curve,\n",
    "                 diesel_cost,  # diesel generator capital cost, USD/kW rated power\n",
    "                 discount_rate,\n",
    "                 n_chg,  # charge efficiency of battery\n",
    "                 n_dis,  # discharge efficiency of battery\n",
    "                 battery_cost,  # battery capital cost, USD/kWh of storage capacity\n",
    "                 pv_cost,  # PV panel capital cost, USD/kW peak power\n",
    "                 charge_controller,  # PV charge controller cost, USD/kW peak power, set to 0 if already included in pv_cost\n",
    "                 pv_inverter,  # PV inverter cost, USD/kW peak power, set to 0 if already included in pv_cost\n",
    "                 pv_life,  # PV panel expected lifetime, years\n",
    "                 diesel_life,  # diesel generator expected lifetime, years\n",
    "                 pv_om,  # annual OM cost of PV panels\n",
    "                 diesel_om,  # annual OM cost of diesel generator\n",
    "                 battery_inverter_cost,\n",
    "                 battery_inverter_life,\n",
    "                 dod_max,  # maximum depth of discharge of battery\n",
    "                 inv_eff,  # inverter_efficiency\n",
    "                 lpsp_max,  # maximum loss of load allowed over the year, in share of kWh\n",
    "                 diesel_limit,\n",
    "                 full_life_cycles,\n",
    "                 start_year,\n",
    "                 end_year,\n",
    "                 ):\n",
    "\n",
    "    demand = load_curve.sum()\n",
    "\n",
    "    # The following lines defines the solution space for the Particle Swarm Optimization (PSO) algorithm\n",
    "    battery_bounds = [0, 5 * demand / 365]\n",
    "    pv_bounds = [0, 5 * max(load_curve)]\n",
    "    diesel_bounds = [0.5, max(load_curve)]\n",
    "    \n",
    "    min_bounds = np.array([pv_bounds[0], battery_bounds[0], diesel_bounds[0]])\n",
    "    max_bounds = np.array([pv_bounds[1], battery_bounds[1], diesel_bounds[1]])\n",
    "    bounds = Bounds(min_bounds, max_bounds)\n",
    "\n",
    "    # Create a series of the hour numbers (0-24) for one year\n",
    "    hour_numbers = np.empty(8760)\n",
    "    for i in range(365):\n",
    "        for j in range(24):\n",
    "            hour_numbers[i * 24 + j] = j\n",
    "\n",
    "    def opt_func(X):\n",
    "        global additional_values_storage  # Use global variable to store additional values\n",
    "        results = find_least_cost_option(X, hourly_temp, hourly_ghi, hour_numbers,\n",
    "                                         load_curve, inv_eff, n_dis, n_chg, dod_max,\n",
    "                                         diesel_price, end_year, start_year, pv_cost, charge_controller, pv_inverter, pv_om,\n",
    "                                         diesel_cost, diesel_om, battery_inverter_life, battery_inverter_cost, diesel_life, pv_life,\n",
    "                                         battery_cost, discount_rate, lpsp_max, diesel_limit, full_life_cycles)\n",
    "        \n",
    "        lcoe = results[0]\n",
    "        additional_values_storage = results[1:]  # Capture additional values\n",
    "                                       \n",
    "        return lcoe\n",
    "\n",
    "    minimizer_kwargs = {\"method\": \"BFGS\"}\n",
    "    pv_init = sum(pv_bounds) / 2\n",
    "    battery_init = sum(battery_bounds) / 2\n",
    "    diesel_init = sum(diesel_bounds) / 2\n",
    "    x0 = [pv_init, battery_init, diesel_init]\n",
    "    \n",
    "    result = differential_evolution(opt_func, bounds, popsize=15, init='latinhypercube')  # init='halton' on newer env\n",
    "\n",
    "    best_solution = result.x\n",
    "    lcoe = opt_func(best_solution)  # This call will also update additional_values_storage\n",
    "    \n",
    "    return {\n",
    "        \"best_solution\": best_solution,\n",
    "        \"lcoe\": lcoe,\n",
    "        \"additional_values\": additional_values_storage\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81470b0",
   "metadata": {},
   "source": [
    "The following line will execute the function optimizer_de and store the results in the variable ret. It finishes with a message on the expected LCOE and the install capacities for Solar Panels, Batteries and diesel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62108d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = optimizer_de(diesel_price=diesel_price, \n",
    "                   hourly_ghi=hourly_ghi,\n",
    "                   hourly_temp=hourly_temp,\n",
    "                   load_curve=load_curve,\n",
    "                   start_year=start_year,\n",
    "                   end_year=end_year,\n",
    "                   discount_rate=discount_rate,\n",
    "                   diesel_cost=diesel_cost,  \n",
    "                   battery_cost=battery_cost,  \n",
    "                   full_life_cycles=full_life_cycles, \n",
    "                   battery_inverter_cost=battery_inverter_cost,  \n",
    "                   pv_cost=pv_cost,  \n",
    "                   pv_inverter=pv_inverter, \n",
    "                   charge_controller=charge_controller, \n",
    "                   diesel_limit=diesel_limit, \n",
    "                   lpsp_max=lpsp_max,\n",
    "                   inv_eff=inv_eff,\n",
    "                   n_chg=n_chg,\n",
    "                   n_dis=n_dis,\n",
    "                   dod_max=dod_max,\n",
    "                   pv_om=pv_om,\n",
    "                   diesel_om=diesel_om,\n",
    "                   battery_inverter_life=battery_inverter_life,\n",
    "                   pv_life=pv_life,\n",
    "                   diesel_life=diesel_life)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad5509",
   "metadata": {},
   "source": [
    "Examining some parameters within the ret variable provides insight into the optimization's progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best LCOE: {} USD/kWh'.format(round(ret[\"lcoe\"],3)))\n",
    "print('Best PV capacity: {} kW'.format(round(ret[\"best_solution\"][0],1)))\n",
    "print('Best Battery capacity: {} kWh'.format(round(ret[\"best_solution\"][1],1)))\n",
    "print('Best Diesel capacity: {} kW'.format(round(ret[\"best_solution\"][2],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost_labour = round(ret[\"best_solution\"][0],1) * labour_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c6f8a",
   "metadata": {},
   "source": [
    "## 6. Distribution Network Sizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d4d75",
   "metadata": {},
   "source": [
    "This section will define quantities for the distribution grid and poles in the minigrid. The required data includes the cluster of the minigrid and the geolocation of the households. The following code explanation will clarify how it can be adapted with own data. The first step involves exploring the data to identify relevant attributes. For instance, the \"Polygones\" file likely contains attributes that describe the polygon geometry of a cluster. We can start by examining the GeoPandas file to understand the available attributes and then retrieve the geometry information for the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_polygons.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556fa30b",
   "metadata": {},
   "source": [
    "The following steps involve using the \"COMUNIDAD\" column to identify the corresponding multipolygon shape from the \"geometry\" column. As mentioned earlier, the retrieved demand data pertains to a specific community within the administrative area of San Gaspar Ixchil. Therefore, the relevant geometry is the one associated with the community named \"ALDEA MANAJA\" within this area. It's important to note that all the spatial analysis discussed here was conducted  with QGIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5eb4c",
   "metadata": {},
   "source": [
    "### Setting up households layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6838033",
   "metadata": {},
   "source": [
    "The households layer was previously uploaded as Polygon Layer. The following lines changed the geometry to point and defines a new layer *households_centroids* with the *target_crs* for Guatemala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219caee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "households_centroids_crs = households.copy()\n",
    "households_centroids_crs[\"geometry\"] =  households['geometry'].centroid\n",
    "households_centroids = households_centroids_crs.to_crs(target_crs)\n",
    "households_centroids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227781a-4ea2-42bf-adc6-b651a583aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_data = cluster_polygons.to_crs(target_crs)\n",
    "polygon_data = polygon_data.iloc[0]\n",
    "polygon = polygon_data['geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3d3ea",
   "metadata": {},
   "source": [
    "#### Trunk Line Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4598b0c8",
   "metadata": {},
   "source": [
    "This process outlines a method for generating a primary trunk line for settlements represented by polygon boundaries. \n",
    "\n",
    "1. **Boundary Points**: The user defines a spacing distance (default 50 meters) to create a set of evenly spaced points along the settlement polygon boundary.\n",
    "2. **Voronoi Polygons**: These points are used to divide the settlement polygon into smaller regions called Voronoi polygons.\n",
    "3. **Initial Trunk Line**: Edges of the Voronoi polygons are extracted, but any edge touching the settlement boundary is removed. This creates a preliminary version of the primary trunk line.\n",
    "4. **Simplifying the Trunk Line**: Intersections where the trunk line branches off are identified. Only segments of the trunk line meeting these criteria are kept:\n",
    "    * Located between two identified intersections.\n",
    "    * Longer than a user-specified distance threshold.\n",
    "5. **Splitting the Trunk Line**: The identified intersections are used to split the primary trunk line into separate segments. Any remaining long segments exceeding a user-defined distance threshold are also split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trunk line(s)\n",
    "trunk_lines = create_trunk_line(polygon, spacing=150, plot=True)\n",
    "\n",
    "# Simplify the trunk line(s)\n",
    "trunk_lines, intersects = simplify_trunk_lines(trunk_lines, length_removal=200, split_distance=750, plot=False)\n",
    "\n",
    "trunk_lines_gdf = gpd.GeoDataFrame(geometry=trunk_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which part of the polygon belongs to which part of the trunk line(s)\n",
    "voronois = voronoi_areas(trunk_lines_gdf, polygon, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66070b",
   "metadata": {},
   "source": [
    "#### Pole locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995a613",
   "metadata": {},
   "source": [
    "With the voronoi areas, now the focus is on identifying poles to where households will be connected. In each sub-area of the settlement polygon:\n",
    "1. A mesh of evenly spaced points (default distance = 50 m) are created\n",
    "2. Points are aligned to the x- and y-axis of the minimum bounding rectangle that can encapsulate the sub-area.\n",
    "3. Any point that is close to the primary trunk line (default distance = 25 m) is excluded, as it is assumed that buildings within this distance would connect to a pole along the primary trunk line.\n",
    "4. Buildings are assigned to the nearest of the candidate poles created in the previous step.\n",
    "5. Finally, a Minimum Spanning Tree is created using NetworkX, to identify the secondary lines. The weights of the MST are assigned to favor in order:\n",
    "    +  lines that are (near) orthogonal to the primary trunk\n",
    "    + lines that are (near) parallel to the primary trunk \n",
    "    + diagonal lines \n",
    "    \n",
    "The MST is run iteratively, testing the removal of poles to which no building was assigned until the shortest MST has been achieved (i.e. no more of the poles without households can be removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdcbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trunk_p = []\n",
    "assigned_p = []\n",
    "lv_l = []\n",
    "service_l = []\n",
    "mst_p = []\n",
    "all_p = []\n",
    "long_services = 0\n",
    "\n",
    "multi_trunks = []\n",
    "multi_trunks_len = []\n",
    "\n",
    "multi_secondary = []\n",
    "multi_secondary_len = []\n",
    "\n",
    "multi_service = []\n",
    "multi_service_len = []\n",
    "\n",
    "multi_poles = []\n",
    "multi_all_poles = []\n",
    "\n",
    "# Iterate over each part of the trunk line \n",
    "for id in range(len(trunk_lines)):\n",
    "    all_poles, trunk_poles, poles, angle_radians_w, angle_radians_l = create_candidate_poles(voronois[id], trunk_lines[id], pole_dist, \n",
    "                                                                                             buffer=15, plot=True)\n",
    "\n",
    "    # print(trunk_poles)\n",
    "    \n",
    "    trunk_p += trunk_poles\n",
    "    all_p += all_poles\n",
    "        \n",
    "    polygon_households = households_centroids.clip(voronois[id])\n",
    "\n",
    "    # Ensure households are not MultiPoint\n",
    "    polygon_households['geometry'] = polygon_households['geometry'].apply(convert_multipoint_to_point)\n",
    "\n",
    "    assigned_poles, service_drops = assign_households(all_poles, polygon_households)\n",
    "\n",
    "    assigned_p += all_poles\n",
    "    service_l += service_drops\n",
    "\n",
    "    for s in service_drops:\n",
    "        if s.length > 70:\n",
    "            long_services += 1\n",
    "\n",
    "    weight = 0.5  # Weighting factor for the MST\n",
    "\n",
    "    lv_lines, mst_poles = lv_lines_mst(all_poles, trunk_poles, assigned_poles, angle_radians_w, angle_radians_l, weight, plot=False)\n",
    "\n",
    "    lv_gdf=gpd.GeoSeries(lv_lines)\n",
    "    lv_gdf = lv_gdf.buffer(10)\n",
    "    all_pole_gdf=gpd.GeoSeries(all_poles)\n",
    "    intersecting_points = []\n",
    "    # Loop over each point in points_gs\n",
    "    for point in all_pole_gdf:\n",
    "        # Check if this point intersects with any line in lines_gs\n",
    "        if lv_gdf.intersects(point).any():\n",
    "            intersecting_points.append(point)\n",
    "    for p in trunk_poles:\n",
    "        if p not in intersecting_points:\n",
    "            intersecting_points.append(p)\n",
    "\n",
    "    lv_l += lv_lines\n",
    "    mst_p += intersecting_points # mst_poles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02529008",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85b846",
   "metadata": {},
   "source": [
    "Geometry results from the sizing model (distribution networ and poles) are appended into a list and then store in geopandas format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ad47e",
   "metadata": {},
   "source": [
    "Appending geometry results from previous sizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_all_poles.append(MultiPoint(all_p))\n",
    "\n",
    "multi_trunks.append(MultiLineString(trunk_lines))\n",
    "multi_trunks_len.append(MultiLineString(trunk_lines).length)\n",
    "\n",
    "multi_secondary.append(MultiLineString(lv_l))\n",
    "multi_secondary_len.append(MultiLineString(lv_l).length)\n",
    "\n",
    "multi_service.append(MultiLineString(service_l))\n",
    "multi_service_len.append(MultiLineString(service_l).length)\n",
    "\n",
    "multi_poles.append(MultiPoint(mst_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b71c53",
   "metadata": {},
   "source": [
    "Assigning appended geometry results to GeoPandas format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd72459",
   "metadata": {},
   "outputs": [],
   "source": [
    "trunks_gdf = gpd.GeoDataFrame()\n",
    "trunks_gdf['Length'] = multi_trunks_len\n",
    "trunks_gdf['Type'] = \"Trunk Line\"\n",
    "trunks_gdf.geometry = multi_trunks\n",
    "trunks_gdf.set_crs(target_crs, inplace=True)\n",
    "trunks_gdf['Community'] = community\n",
    "\n",
    "secondary_gdf = gpd.GeoDataFrame()\n",
    "secondary_gdf['Length'] = multi_secondary_len\n",
    "secondary_gdf['Type'] = \"Secondary Line\"\n",
    "secondary_gdf.geometry = multi_secondary\n",
    "secondary_gdf.set_crs(target_crs, inplace=True)\n",
    "secondary_gdf['Community'] = community\n",
    "\n",
    "service_gdf = gpd.GeoDataFrame()\n",
    "service_gdf['Length'] = multi_service_len\n",
    "service_gdf['Type'] = \"Service Line\"\n",
    "service_gdf.geometry = multi_service\n",
    "service_gdf.set_crs(target_crs, inplace=True)\n",
    "service_gdf['Community'] = community\n",
    "\n",
    "poles_gdf = gpd.GeoDataFrame()\n",
    "poles_gdf.geometry = multi_poles\n",
    "for i, multi_pole in enumerate(multi_poles):\n",
    "    num_poles = len(multi_pole.geoms)\n",
    "poles_gdf['No. Poles'] = num_poles\n",
    "poles_gdf.set_crs(target_crs, inplace=True)\n",
    "poles_gdf['Community'] = community\n",
    "poles_gdf.to_crs(4326, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1422f",
   "metadata": {},
   "source": [
    "Finally, all the individual MultiLineString GeoDataGrames can be merged into a single GeoDataFrame for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_grid_gdf = gpd.GeoDataFrame(pd.concat([trunks_gdf, secondary_gdf, service_gdf], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a134c9",
   "metadata": {},
   "source": [
    "The *total_grid_df* contains the three different kind of connection, and it is one of the main outputs of the OnSSET-MG tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c688a",
   "metadata": {},
   "source": [
    "### Cost of distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15a2f7",
   "metadata": {},
   "source": [
    "Earlier in the notebook *cost_grid_km* was defined. Now, the cost of the distribution grid can be estimated following the next equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31791935",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_grid = cost_grid_km * (sum(trunks_gdf[\"Length\"])/1000 + sum(secondary_gdf[\"Length\"])/1000)\n",
    "cost_service_drops = con_cost*(sum(service_gdf['Length'])/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcf74a",
   "metadata": {},
   "source": [
    "*Cost_pole* was also defined, and it can also be called in this part to estimate the total cost of installing all the poles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost_poles = cost_pole * sum(poles_gdf[\"No. Poles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf597b",
   "metadata": {},
   "source": [
    "With the two defined variables *cost_grid* and *total_cost_poles*, the total cost of the grid is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost_grid = cost_grid + cost_service_drops + total_cost_poles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11915b33",
   "metadata": {},
   "source": [
    "And Finally, the annual cost of Operationan & Maintenance are calculated based on a percentage of the total Capital Costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8163476",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_om_grid = grid_om * total_cost_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd63d90",
   "metadata": {},
   "source": [
    "The function to define de LCOE for the distribution grid can be calculated from the set of functions available in the OnSSET-MG tool. Notices that within the function, the time life of the grid was set in 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c69787",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcoe_distribution = calculate_distribution_lcoe(end_year=end_year, \n",
    "                            start_year=start_year, \n",
    "                            annual_demand=annual_demand, \n",
    "                            distribution_cost=total_cost_grid, \n",
    "                            om_costs=total_om_grid, \n",
    "                            distribution_life=30, \n",
    "                            discount_rate=discount_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f9439-5db3-48a4-985d-c4a8f48ee51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_life = end_year - start_year\n",
    "total_sga = 0\n",
    "for year in range(project_life):\n",
    "    total_sga += total_cost_sga / ((1 + discount_rate) ** year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe121d90",
   "metadata": {},
   "source": [
    "Transportation costs are defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25292ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transportation_costs = trans_cost*len(households)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed53dd9",
   "metadata": {},
   "source": [
    "## 7. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7db392",
   "metadata": {},
   "source": [
    "From the previous section there are several outputs of interest, but in this part the focus will be on the variable *ret* and the GeoPandas dataframes *total_grid_gdf* and *poles_gdf*. On this regard, a better presentation of the results could be as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53dc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Name\": [\"PV Capacity [kWp]\",\n",
    "             \"Battery capacity [kWh]\", \n",
    "             \"Diesel Capacity [kW]\",\n",
    "             \"Annual diesel fuel usage [litre]\",\n",
    "              \n",
    "             \"Trunk Line [km]\",\n",
    "             \"Laterals [km]\",\n",
    "             \"Service lines [km]\",\n",
    "             \"No Poles\",         \n",
    "             \n",
    "             \"CAPEX generation [USD]\",\n",
    "             \"CAPEX Distribution [USD]\",\n",
    "             \"Cost of Labour [USD]\",\n",
    "             \"Cost of Transport [USD]\",\n",
    "             \"Total CAPEX [USD]\",\n",
    "             \n",
    "             \"OPEX Generation [USD]\",\n",
    "             \"OPEX Distribution [USD]\",\n",
    "             \"OPEX SG&A [USD]\",\n",
    "             \"Total OPEX [USD]\",\n",
    "             \"Annual OPEX [USD]\",\n",
    "             \"NPC [USD]\",\n",
    "             \n",
    "             \"lcoe [USD/kWh]\",\n",
    "       \n",
    "            ],\n",
    "    \n",
    "    \n",
    "    \"Value\": [round(ret[\"best_solution\"][0],1), #PV_Capacity\n",
    "              round(ret[\"best_solution\"][1],1),  #Battery Capacity\n",
    "              round(ret[\"best_solution\"][2],1), #Diesel Capacity\n",
    "              round(ret[\"additional_values\"][10],2), #Diesel fuel usage\n",
    "              \n",
    "              round(sum(trunks_gdf[\"Length\"])/1000,1), #kilometers_grid_main_line\n",
    "              round(sum(secondary_gdf[\"Length\"])/1000,1), #kilometers_grid_secondary_lines\n",
    "              round(sum(service_gdf[\"Length\"])/1000,1),#kilometers_services_drops\n",
    "              sum(poles_gdf[\"No. Poles\"]), #Number of poles\n",
    "              \n",
    "              round(ret[\"additional_values\"][2],3), # CAPEX of generation - total_cost_labour - transportation_costs, #Cost of Assets\n",
    "              round(total_cost_grid,0), # CAPEX of distribution\n",
    "              total_cost_labour, #Cost of Labour\n",
    "              transportation_costs, #Cost of transport\n",
    "              round(total_cost_grid,0) + math.ceil(round(ret[\"additional_values\"][2],3)) + total_cost_labour + transportation_costs, #Total_capex\n",
    "              \n",
    "              round(ret[\"additional_values\"][4],0) + round(ret[\"additional_values\"][3],0), #Total OPEX Generation\n",
    "              round(lcoe_distribution[2],0), #Total OPEX Distribution\n",
    "              round(total_sga, 0),\n",
    "              round(ret[\"additional_values\"][4] + ret[\"additional_values\"][3] + lcoe_distribution[2] + total_sga, 0), #Total OPEX\n",
    "              round(ret[\"additional_values\"][-1] + lcoe_distribution[-1] + total_cost_sga, 0), #Annual OPEX\n",
    "              round(ret[\"additional_values\"][9] + lcoe_distribution[3] + total_sga + total_cost_labour + transportation_costs, 0), # Net Present Costs\n",
    "              \n",
    "              round(ret[\"lcoe\"],3) + round(lcoe_distribution[0],3), #lcoe_generation + lcoe_distribution\n",
    "             ]\n",
    "}\n",
    "\n",
    "results_pd = pd.DataFrame(results, columns=[\"Name\", \"Value\"])\n",
    "\n",
    "# Assign result columns to the original community aplha shape\n",
    "for key, value in results_pd.set_index('Name')['Value'].to_dict().items():\n",
    "    cluster_polygons[key] = value\n",
    "\n",
    "results_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd885f5",
   "metadata": {},
   "source": [
    "### 7. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9be05",
   "metadata": {},
   "source": [
    "The results can be exported. Specifically, CSV files will be generated from some of the dataframes, and the same process can be applied to the GeoDataFrames. Earlier in the notebook the *outpath* folder was defined to stored out results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26357590",
   "metadata": {},
   "source": [
    "#### Exporting summary results as .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = community + \"_Results\"\n",
    "results_pd.to_csv(os.path.join(outpath, name_file +\".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450ac3b",
   "metadata": {},
   "source": [
    "#### Exporting simulated distribution lines into a .gpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_gpd_file_d = os.path.join(outpath, \"{} distribution_grid.gpkg\".format(community))\n",
    "name_gpd_file_c = os.path.join(outpath, \"{} results.gpkg\".format(community))\n",
    "\n",
    "## Export trunk lines\n",
    "trunks_gdf.to_crs(origin_crs, inplace=True)\n",
    "trunks_gdf.to_file(name_gpd_file_d, layer='Trunk_line', driver='GPKG')\n",
    "\n",
    "## Export laterals\n",
    "secondary_gdf.to_crs(origin_crs, inplace=True)\n",
    "secondary_gdf.to_file(name_gpd_file_d, layer='Laterals', driver='GPKG')\n",
    "\n",
    "## Export service lines\n",
    "service_gdf.to_crs(origin_crs, inplace=True)\n",
    "service_gdf.to_file(name_gpd_file_d, layer='Service_lines', driver='GPKG')\n",
    "\n",
    "## Export poles\n",
    "#poles_gdf.to_crs(origin_crs, inplace=True)\n",
    "poles_gdf.to_file(name_gpd_file_d, layer='Poles', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9bdda",
   "metadata": {},
   "source": [
    "#### Exporting community with results into a .gpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_polygons.to_file(name_gpd_file_c, layer=community, driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598220-2337-40bc-87d8-cf7668f30b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
